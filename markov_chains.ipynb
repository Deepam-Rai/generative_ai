{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from scipy.sparse import dok_matrix\n",
    "from constants import *\n",
    "from utils import get_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./data/Shakespeare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-wise tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Given text, returns it as list of tokens.\n",
    "    \"\"\"\n",
    "    return list(text)\n",
    "\n",
    "\n",
    "def textify_tokens(tokens: list) -> str:\n",
    "    \"\"\"\n",
    "    Given list of tokens, returns them as text str.\n",
    "    \"\"\"\n",
    "    return ''.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 1215376 \t Unique tokens: 65\n"
     ]
    }
   ],
   "source": [
    "text = get_text([data_path])\n",
    "\n",
    "text_as_tokens = tokenize_text(text)\n",
    "tokens = list(set(text_as_tokens))\n",
    "tokens.sort()\n",
    "vocab_size = len(tokens)\n",
    "token_to_id = {word: idx for idx, word in enumerate(tokens)}\n",
    "\n",
    "print(f\"Corpus size: {len(text_as_tokens)} \\t Unique tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-matrix\n",
    "Matrix that maps last k-words to the immediate next word.  \n",
    "Suppose we were taking words as tokens.  \n",
    "Example: for text, \"Let it be\" and `k=4`, the matrix would look like:\n",
    "```text\n",
    ".           \"L\"   \"e\"  \"t\"  \"i\"  \"b\"  \" \"\n",
    "[\"Let \"] :   0     0    0    1    0    0\n",
    "[\"et i\"] :   0     0    1    0    0    0\n",
    "[\"t it\"] :   0     0    0    0    0    1\n",
    "[\" it \"] :   0     0    0    0    1    0\n",
    "[\"it b\"] :   0     1    0    0    0    0\n",
    "[\"t be\"] :   0     0    0    0    0    0\n",
    "```\n",
    "Of course there are other mappings possible, but above ones are those present in the example sentence.  \n",
    "Since our matrix is going to be sparse we use `scipy.dok_matrix`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_matrix(k: int):\n",
    "    \"\"\"\n",
    "    Creates a matrix that maps conditional probability of next word in the sentence,\n",
    "    given past k words in the sentence.\n",
    "    :param k: past-k words to be considered\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if k < 1:\n",
    "        raise ValueError(\"k should be greater than 0.\")\n",
    "    seq_of_k = [''.join(text_as_tokens[i:i+k]) for i in range(len(text_as_tokens)-k)]\n",
    "    set_seq_of_k = list(set(seq_of_k))\n",
    "    set_seq_of_k.sort()\n",
    "    seq_of_k_to_id = {s: idx for idx, s in enumerate(set_seq_of_k)}\n",
    "    k_matrix = dok_matrix((len(set_seq_of_k), vocab_size))\n",
    "    for i, last_k in enumerate(seq_of_k[:-k]):\n",
    "        last_k_words_row = seq_of_k_to_id[last_k]\n",
    "        next_word_col = token_to_id[text_as_tokens[i + k]]\n",
    "        k_matrix[last_k_words_row, next_word_col] += 1\n",
    "    return k_matrix, seq_of_k_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next_token_after_seq(k_matrix, seq_of_k_to_id: dict, seq: str, alpha: float = 0) -> str:\n",
    "    \"\"\"\n",
    "    Given sequence of last k tokens, samples next token\n",
    "    :param seq:\n",
    "    :param alpha: Creativity hyperparameter, large the value => distribution approches uniormity => choice of random token\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if seq not in seq_of_k_to_id:\n",
    "        # markov chains has not seen any following token to this sequence\n",
    "        return random.choice(tokens)\n",
    "    next_token_vector = k_matrix[seq_of_k_to_id[seq]] + alpha\n",
    "    likelihoods = next_token_vector/next_token_vector.sum()\n",
    "    return random.choices(tokens, likelihoods.toarray()[0])[0]\n",
    "\n",
    "def stochastic_chain(k_matrix, seq_of_k_to_id: dict, seed: str = None, chain_length: int = 15):\n",
    "    \"\"\"\n",
    "    Returns sentence with added tokens equal to 'chain_length'.\n",
    "    The last k-token phrase of the seed sentence need to be present in some part of the training dataset.\n",
    "\n",
    "    :param seed: If None, randomly generates seed sentence.\n",
    "    :param chain_length: Added tokens to be generated.\n",
    "    :return: seed sentence + generated sentence.\n",
    "    \"\"\"\n",
    "    k = len(list(seq_of_k_to_id.keys())[0])\n",
    "    if seed is None:\n",
    "        seed = random.choice(list(seq_of_k_to_id.keys()))\n",
    "    current_tokens = tokenize_text(seed)\n",
    "    if len(current_tokens) < k:\n",
    "        raise ValueError(f\"Seed length must be at-least as long as {k}\")\n",
    "    sentence = seed\n",
    "    current_tokens = current_tokens[-k:]\n",
    "    if seq_of_k_to_id.get(textify_tokens(current_tokens), None) is None:\n",
    "        raise ValueError(\"The last k-word phrase of the seed sentence need to be present in some part of the training dataset.\")\n",
    "    for _ in range(chain_length):\n",
    "        next_token = sample_next_token_after_seq(k_matrix, seq_of_k_to_id, seq=textify_tokens(current_tokens))\n",
    "        sentence += next_token\n",
    "        current_tokens = current_tokens[1:] + [next_token]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65  1-token-sequences have been mapped to 65 tokens.\n",
      "1481  2-token-sequences have been mapped to 65 tokens.\n",
      "12249  3-token-sequences have been mapped to 65 tokens.\n",
      "53249  4-token-sequences have been mapped to 65 tokens.\n",
      "148302  5-token-sequences have been mapped to 65 tokens.\n",
      "300238  6-token-sequences have been mapped to 65 tokens.\n",
      "478117  7-token-sequences have been mapped to 65 tokens.\n",
      "656104  8-token-sequences have been mapped to 65 tokens.\n",
      "812085  9-token-sequences have been mapped to 65 tokens.\n",
      "933034  10-token-sequences have been mapped to 65 tokens.\n",
      "1020602  11-token-sequences have been mapped to 65 tokens.\n",
      "1081144  12-token-sequences have been mapped to 65 tokens.\n",
      "1121676  13-token-sequences have been mapped to 65 tokens.\n",
      "1148692  14-token-sequences have been mapped to 65 tokens.\n"
     ]
    }
   ],
   "source": [
    "k_list = list(range(1, 15))\n",
    "# k_list = [7]\n",
    "k_calculated = {}\n",
    "for k in k_list:\n",
    "    k_matrix, seq_of_k_to_id = get_k_matrix(k=k)\n",
    "    print(f\"{len(seq_of_k_to_id)}  {k}-token-sequences have been mapped to {vocab_size} tokens.\")\n",
    "    k_calculated[k] = (k_matrix, seq_of_k_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 1\n",
      "oul mestothald schersheang y mens f\n",
      "Any this\n",
      "My INIsheff gemashelly waderearleisweinde towat s lleavi\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 2\n",
      "EVAUREL:\n",
      "Supoke the not night hiceiring offech beare eveign prale and, ing and mortessio.\n",
      "\n",
      "Dide and th\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 3\n",
      "kitch\n",
      "The grow; but morship.\n",
      "\n",
      "LUCIO:\n",
      "I with alls,\n",
      "To Baption ship clost that your quick moth to thou ho\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 4\n",
      "? Prithmetimes not be sorrow the for than hope it for life,--for one's sometime bettery March times?\n",
      "\n",
      "AR\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 5\n",
      "ere England what's o'clock?\n",
      "\n",
      "BRUTUS:\n",
      "Do not so,\n",
      "That walk in her nature,\n",
      "The more; I'll desire that atten\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 6\n",
      "sbehaved and then they are rebels would whip your majesty.\n",
      "\n",
      "First Murderer:\n",
      "Wherefore deep:\n",
      "I'll render fi\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 7\n",
      "most power to lie before theme of his death,\n",
      "I will give me loved the old folks, many friends, God speed at\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 8\n",
      "at those my babies lulls asleep! the smiles on the adversaries,\n",
      "Which, thou know'st it well they return.\n",
      "\n",
      "AD\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 9\n",
      "at is become of me?\n",
      "\n",
      "RIVERS:\n",
      "And so shall make\n",
      "False accusation overweigh,\n",
      "That you think it. Hark! the fatal\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 10\n",
      " victory:\n",
      "Once more, take her mercy in thy cunnings and\n",
      "The crown and only son:\n",
      "If I may ever know thou canst \n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 11\n",
      "ng father:\n",
      "The sister to my wife.\n",
      "\n",
      "LUCENTIO:\n",
      "And therefore hurt not: but\n",
      "your people\n",
      "But tie him not to be gone\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 12\n",
      "hind your back, than to your face.\n",
      "\n",
      "KING RICHARD III:\n",
      "Who intercepts my expedition?\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "Why, what \n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 13\n",
      "ou had not found me here so musical:\n",
      "Let me excuse me, and believe me so,\n",
      "My mirth it much displeased\n",
      "That you ta\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 14\n",
      ", speak too:\n",
      "Baccare! you are marvellous forward.\n",
      "\n",
      "PETRUCHIO:\n",
      "Why, therefore Warwick came to seek you out;\n",
      "And the\n",
      "------------------------- END\n"
     ]
    }
   ],
   "source": [
    "for k, calculated in k_calculated.items():\n",
    "    k_matrix, seq_of_k_to_id = calculated\n",
    "    generated = stochastic_chain(\n",
    "        k_matrix=k_matrix,\n",
    "        seq_of_k_to_id=seq_of_k_to_id,\n",
    "        seed=None,\n",
    "        chain_length=100\n",
    "    )\n",
    "    print(f\"\\n------------------------- GENERATED SENTENCE -- k = {k}\")\n",
    "    print(generated)\n",
    "    print(\"------------------------- END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-wise tokenization\n",
    "Taking each word as a token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text: str) -> list:\n",
    "    \"\"\"\n",
    "    Given text, returns it as list of tokens.\n",
    "    \"\"\"\n",
    "    tokens = process_text(text=text)\n",
    "    tokens = tokens.split(' ')\n",
    "    tokens = list(filter(lambda x: x != '', tokens))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def textify_tokens(tokens: list) -> str:\n",
    "    \"\"\"\n",
    "    Given list of tokens, returns them as text str.\n",
    "    \"\"\"\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "puncs = {\n",
    "    '\\n': '\\n', '\\t': '\\t', '.': '. ', '-': '-', ',': ', ', '!': '! ', '?': '?' ,\n",
    "    '“': '“', '”': '” ',  '(': '(', '—': '—', ')': ') ', '/': '/', '\\'': '\\'', ';': '; ',\n",
    "    ':': ': ', '‘': '‘', '$': '$'\n",
    "}\n",
    "\n",
    "\n",
    "def process_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Inserts space before and after punctuations.\n",
    "    :param text:\n",
    "    :return: cleaned text\n",
    "    \"\"\"\n",
    "    cleaned_text = text\n",
    "    for punc in puncs:\n",
    "        cleaned_text = cleaned_text.replace(punc, f' {punc} ')\n",
    "    cleaned_text = re.sub(\"[ ]+\", \" \", cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def postprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Tries to unddo opposite of the processings done on input.\n",
    "    \"\"\"\n",
    "    cleaned_text = text\n",
    "    for punc, pre_punc in puncs.items():\n",
    "        cleaned_text = cleaned_text.replace(f' {punc}', pre_punc)\n",
    "    cleaned_text = re.sub(\"[ ]+\", \" \", cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 329579 \t Unique tokens: 14343\n"
     ]
    }
   ],
   "source": [
    "text = get_text([data_path])\n",
    "text_as_tokens = tokenize_text(text)\n",
    "tokens = list(set(text_as_tokens))\n",
    "tokens.sort()\n",
    "vocab_size = len(tokens)\n",
    "token_to_id = {word: idx for idx, word in enumerate(tokens)}\n",
    "\n",
    "print(f\"Corpus size: {len(text_as_tokens)} \\t Unique tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-matrix\n",
    "Matrix that maps last k-words to the immediate next word.  \n",
    "Example: for text, \"To be or not to be\" and `k=4`, the matrix would look like:\n",
    "```text\n",
    ".                            \"To\"   \"be\"  \"not\"  \"or\"  \"to\"\n",
    "[\"To\", \"be\", \"or\", \"not\"] :   0      0     0      0     1\n",
    "[\"be\", \"or\", \"not\", \"to\"] :   0      1     0      0     0\n",
    "[\"or\", \"not\", \"to\", \"be\"] :   0      0     0      0     0\n",
    "```\n",
    "Of course there are other mappings possible, but above ones are those present in the example sentence.  \n",
    "Since our matrix is going to be sparse we use `scipy.dok_matrix`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_matrix(k: int):\n",
    "    \"\"\"\n",
    "    Creates a matrix that maps conditional probability of next word in the sentence,\n",
    "    given past k words in the sentence.\n",
    "    :param k: past-k words to be considered\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if k < 1:\n",
    "        raise ValueError(\"k should be greater than 0.\")\n",
    "    seq_of_k = [' '.join(text_as_tokens[i:i+k]) for i in range(len(text_as_tokens)-k)]\n",
    "    set_seq_of_k = list(set(seq_of_k))\n",
    "    set_seq_of_k.sort()\n",
    "    seq_of_k_to_id = {s: idx for idx, s in enumerate(set_seq_of_k)}\n",
    "    k_matrix = dok_matrix((len(set_seq_of_k), vocab_size))\n",
    "    for i, last_k in enumerate(seq_of_k[:-k]):\n",
    "        last_k_words_row = seq_of_k_to_id[last_k]\n",
    "        next_word_col = token_to_id[text_as_tokens[i + k]]\n",
    "        k_matrix[last_k_words_row, next_word_col] += 1\n",
    "    return k_matrix, seq_of_k_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next_token_after_seq(k_matrix, seq_of_k_to_id: dict, seq: str, alpha: float = 0) -> str:\n",
    "    \"\"\"\n",
    "    Given sequence of last k tokens, samples next token\n",
    "    :param seq:\n",
    "    :param alpha: Creativity hyperparameter, large the value => distribution approches uniormity => choice of random token\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if seq not in seq_of_k_to_id:\n",
    "        # markov chains has not seen any following token to this sequence\n",
    "        return random.choice(tokens)\n",
    "    next_token_vector = k_matrix[seq_of_k_to_id[seq]] + alpha\n",
    "    likelihoods = next_token_vector/next_token_vector.sum()\n",
    "    return random.choices(tokens, likelihoods.toarray()[0])[0]\n",
    "\n",
    "def stochastic_chain(k_matrix, seq_of_k_to_id: dict, seed: str = None, chain_length: int = 15):\n",
    "    \"\"\"\n",
    "    Returns sentence with added tokens equal to 'chain_length'.\n",
    "    The last k-token phrase of the seed sentence need to be present in some part of the training dataset.\n",
    "\n",
    "    :param seed: If None, randomly generates seed sentence.\n",
    "    :param chain_length: Added tokens to be generated.\n",
    "    :return: seed sentence + generated sentence.\n",
    "    \"\"\"\n",
    "    k = len(tokenize_text(list(seq_of_k_to_id.keys())[0]))\n",
    "    if seed is None:\n",
    "        seed = random.choice(list(seq_of_k_to_id.keys()))\n",
    "    current_tokens = tokenize_text(seed)\n",
    "    generated_tokens = current_tokens\n",
    "    if len(current_tokens) < k:\n",
    "        raise ValueError(f\"Seed length must be at-least as long as {k}\")\n",
    "    current_tokens = current_tokens[-k:]\n",
    "    if seq_of_k_to_id.get(textify_tokens(current_tokens), None) is None:\n",
    "        raise ValueError(\"The last k-word phrase of the seed sentence need to be present in some part of the training dataset.\")\n",
    "    for _ in range(chain_length):\n",
    "        next_token = sample_next_token_after_seq(k_matrix, seq_of_k_to_id, seq=textify_tokens(current_tokens))\n",
    "        generated_tokens.append(next_token)\n",
    "        current_tokens = current_tokens[1:] + [next_token]\n",
    "    sentence = textify_tokens(generated_tokens)\n",
    "    sentence = postprocess_text(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14343 \tmany 1-token-sequences have been mapped to 14343 tokens.\n",
      "106460 \tmany 2-token-sequences have been mapped to 14343 tokens.\n",
      "210180 \tmany 3-token-sequences have been mapped to 14343 tokens.\n",
      "270300 \tmany 4-token-sequences have been mapped to 14343 tokens.\n",
      "299377 \tmany 5-token-sequences have been mapped to 14343 tokens.\n",
      "312964 \tmany 6-token-sequences have been mapped to 14343 tokens.\n"
     ]
    }
   ],
   "source": [
    "k_list = list(range(1, 7))\n",
    "# k_list = [1]\n",
    "k_calculated = {}\n",
    "for k in k_list:\n",
    "    k_matrix, seq_of_k_to_id = get_k_matrix(k=k)\n",
    "    print(f\"{len(seq_of_k_to_id)} \\tmany {k}-token-sequences have been mapped to {vocab_size} tokens.\")\n",
    "    k_calculated[k] = (k_matrix, seq_of_k_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 1\n",
      "preparation. \n",
      " Reignier, Clarence did I will, \n",
      " And welcome home again, in thy earliness doth give thee for my soul, \n",
      "\n",
      " BAPTISTA: Come, make fit his troops, \n",
      " If you of woe obey. \n",
      " Thanks, wagery, lords, on Edward hath look' dst Polixenes; then I have goaded onward. \n",
      " So season. \n",
      "\n",
      " Is very Mab\n",
      "\n",
      "\n",
      " High- a state\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 2\n",
      "s rattling bones, \n",
      " The gods grant them true! \n",
      "\n",
      " RICHARD: \n",
      " These English woes will make them sharp, and, sooth to say I said loose- bodied and the time! \n",
      " Henceforward do your best haste, his blood committed to your hand too much. Servants, leave me but love' s fight with none but thou talk' d Jove' s tooth doth never rankle more\n",
      " Than in my\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 3\n",
      "near, be ne' er so fair, and I' ll pray a thousand prayers for thy death: \n",
      "' Tis he, that should be husband, comes to woo. \n",
      " I' ll away before. \n",
      "\n",
      " CAPULET: \n",
      " Soft! take me with you, best brother?\n",
      "\n",
      " POLIXENES: \n",
      " Then say at once what thou dost know in this. \n",
      " Dost thou love hawking? thou hast hawks will\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 4\n",
      "by guess. \n",
      "\n",
      " KING HENRY VI: \n",
      " I was moved withal. \n",
      "\n",
      " DERBY: \n",
      " Fortune and victory sit on thy helm! \n",
      "\n",
      " RICHMOND: \n",
      " God and your arms be praised, victorious friends, \n",
      " The day is hot, the Capulets abroad, \n",
      " And, touching hers, make blessed my rude hand. \n",
      " Did my heart love till now? forswear it, sight! \n",
      " For I ne' er\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 5\n",
      "conceal' d lady to our cancell' d love?\n",
      "\n",
      " Nurse: \n",
      " O, she is lame! love' s heralds should be thoughts, \n",
      " Which ten times faster glide than the sun' s beams, \n",
      " Driving back shadows over louring hills: \n",
      " Therefore do nimble- pinion' d doves draw love, \n",
      " And therefore hath the wind- swift Cupid wings. \n",
      " Now is the sun upon the highmost hill\n",
      " Of\n",
      "------------------------- END\n",
      "\n",
      "------------------------- GENERATED SENTENCE -- k = 6\n",
      "heart, poor sons, lamented for her, \n",
      " Or the least votary I score my awe, \n",
      " It breathes me of it. \n",
      "\n",
      " CYMBELINE: \n",
      " But those that I forsake old Gaunt, the earth to ever. \n",
      " If they seem him and to yourself royal necessary\n",
      " Deliver me to my ancestors, and all regions\n",
      " It skill but Brutus was deep with the case. \n",
      "\n",
      " Boy: \n",
      " Why do you wring your hands\n",
      "------------------------- END\n"
     ]
    }
   ],
   "source": [
    "for k, calculated in k_calculated.items():\n",
    "    k_matrix, seq_of_k_to_id = calculated\n",
    "    generated = stochastic_chain(\n",
    "        k_matrix=k_matrix,\n",
    "        seq_of_k_to_id=seq_of_k_to_id,\n",
    "        seed=None,\n",
    "        chain_length=80\n",
    "    )\n",
    "    print(f\"\\n------------------------- GENERATED SENTENCE -- k = {k}\")\n",
    "    print(generated)\n",
    "    print(\"------------------------- END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
